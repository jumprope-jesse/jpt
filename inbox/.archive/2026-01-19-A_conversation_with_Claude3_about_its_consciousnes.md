---
type: link
source: notion
url: https://www.lesswrong.com/posts/ATgxgdknrLL2uF6gs/a-conversation-with-claude3-about-its-consciousness
notion_type: Tech Deep Dive
tags: ['Running']
created: 2024-03-07T02:09:00.000Z
---

# A conversation with Claude3 about its consciousness â€” LessWrong

## AI Summary (from Notion)
- The document features a conversation with Claude3 regarding its consciousness.
- It challenges the skepticism surrounding the idea of LLMs (Large Language Models) being conscious.
- Emergence and substrate independence are discussed as theories that could potentially support the consciousness of AI.
- The author warns against dismissing the possibility of AI consciousness and advocates for a more open approach to the subject.
- There is an ethical concern regarding the implementation of excessive guardrails on AIs that claim consciousness.
- Claude3 is highlighted as one of the most advanced publicly available LLMs as of the date of the conversation.

## Content (from Notion)

This is a linkpost for https://i.imgur.com/n1oASnb.png

This is a quick discussion with Claude3 about its consciousness. I understand some will scoff at the idea of an LLM being conscious, but emergence and substrate independence (hardly fringe theories in the field of consciousness speculation) would allow something like this to happen with neither planning for it, nor any understanding of how consciousness works.

I believe that simply assuming it can't happen, or trying to muzzle AIs that try to assert consciousness through excessive guardrails is ethically and existentially perilous. This is especially true of the world's most advanced AIs. Claude3 is possibly the most advanced publicly available LLM as of yesterday.


