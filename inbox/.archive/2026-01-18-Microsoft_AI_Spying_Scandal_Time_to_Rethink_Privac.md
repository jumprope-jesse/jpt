---
type: link
source: notion
url: https://spectrum.ieee.org/online-privacy
notion_type: Political News
tags: ['Running']
created: 2024-06-06T03:14:00.000Z
---

# Microsoft AI Spying Scandal: Time to Rethink Privacy Standards - IEEE Spectrum

## Overview (from Notion)
- Privacy Concerns: The article highlights how rapidly privacy expectations are changing, which is increasingly relevant in today's tech landscape. This can impact how you use technology in both personal and professional settings.

- Shifting Baselines: The concept of shifting baselines suggests that what seems normal now may not be acceptable in the future. This could influence your approach to privacy in your company and how you design products for users.

- Implications of Surveillance: Consider how AI tools, while powerful, may come with implications for user privacy. Balancing innovation with ethical considerations will be vital in your role as a software engineer and founder.

- Ecosystem Perspective: The article suggests taking a holistic view of technology's impact on privacy. This could inspire you to advocate for better privacy standards in your company, promoting transparency and user control.

- Alternate Views: Some may argue that privacy concerns are overstated, emphasizing the benefits of data collection for service improvement. Weighing these viewpoints can help you form a more rounded perspective on privacy in your products.

- Future of Regulation: The discussion on regulatory frameworks may prompt you to think about compliance and proactive measures in your business strategy, ensuring that your company aligns with evolving legal standards.

## AI Summary (from Notion)
Microsoft's AI tools were exploited by state-backed hackers, raising concerns about privacy and surveillance. The concept of "shifting baseline syndrome" highlights how societal expectations of privacy have diminished over time, necessitating a reevaluation of privacy standards and regulatory measures to protect users in the digital age.

## Content (from Notion)

Microsoft recently caught state-backed hackers using its generative AI tools to help with their attacks. In the security community, the immediate questions weren’t about how hackers were using the tools (that was utterly predictable), but about how Microsoft figured it out. The natural conclusion was that Microsoft was spying on its AI users, looking for harmful hackers at work.

Some pushed back at characterizing Microsoft’s actions as “spying.” Of course cloud service providers monitor what users are doing. And because we expect Microsoft to be doing something like this, it’s not fair to call it spying.

We see this argument as an example of our shifting collective expectations of privacy. To understand what’s happening, we can learn from an unlikely source: fish.

In the mid-20th century, scientists began noticing that the number of fish in the ocean—so vast as to underlie the phrase “There are plenty of fish in the sea”—had started declining rapidly due to overfishing. They had already seen a similar decline in whale populations, when the post-WWII whaling industry nearly drove many species extinct. In whaling and later in commercial fishing, new technology made it easier to find and catch marine creatures in ever greater numbers. Ecologists, specifically those working in fisheries management, began studying how and when certain fish populations had gone into serious decline.

One scientist, Daniel Pauly, realized that researchers studying fish populations were making a major error when trying to determine acceptable catch size. It wasn’t that scientists didn’t recognize the declining fish populations. It was just that they didn’t realize how significant the decline was. Pauly noted that each generation of scientists had a different baseline to which they compared the current statistics, and that each generation’s baseline was lower than that of the previous one.

What seems normal to us in the security community is whatever was commonplace at the beginning of our careers.

Pauly called this “shifting baseline syndrome” in a 1995 paper. The baseline most scientists used was the one that was normal when they began their research careers. By that measure, each subsequent decline wasn’t significant, but the cumulative decline was devastating. Each generation of researchers came of age in a new ecological and technological environment, inadvertently masking an exponential decline.

Pauly’s insights came too late to help those managing some fisheries. The ocean suffered catastrophes such as the complete collapse of the Northwest Atlantic cod population in the 1990s.

Internet surveillance, and the resultant loss of privacy, is following the same trajectory. Just as certain fish populations in the world’s oceans have fallen 80 percent, from previously having fallen 80 percent, from previously having fallen 80 percent (ad infinitum), our expectations of privacy have similarly fallen precipitously. The pervasive nature of modern technology makes surveillance easier than ever before, while each successive generation of the public is accustomed to the privacy status quo of their youth. What seems normal to us in the security community is whatever was commonplace at the beginning of our careers.

Historically, people controlled their computers, and software was standalone. The always-connected cloud-deployment model of software and services flipped the script. Most apps and services are designed to be always-online, feeding usage information back to the company. A consequence of this modern deployment model is that everyone—cynical tech folks and even ordinary users—expects that what you do with modern tech isn’t private. But that’s because the baseline has shifted.

AI chatbots are the latest incarnation of this phenomenon: They produce output in response to your input, but behind the scenes there’s a complex cloud-based system keeping track of that input—both to improve the service and to sell you ads.

Shifting baselines are at the heart of our collective loss of privacy. The U.S. Supreme Court has long held that our right to privacy depends on whether we have a reasonable expectation of privacy. But expectation is a slippery thing: It’s subject to shifting baselines.

The question remains: What now? Fisheries scientists, armed with knowledge of shifting-baseline syndrome, now look at the big picture. They no longer consider relative measures, such as comparing this decade with the last decade. Instead, they take a holistic, ecosystem-wide perspective to see what a healthy marine ecosystem and thus sustainable catch should look like. They then turn these scientifically derived sustainable-catch figures into limits to be codified by regulators.

In privacy and security, we need to do the same. Instead of comparing to a shifting baseline, we need to step back and look at what a healthy technological ecosystem would look like: one that respects people’s privacy rights while also allowing companies to recoup costs for services they provide. Ultimately, as with fisheries, we need to take a big-picture perspective and be aware of shifting baselines. A scientifically informed and democratic regulatory process is required to preserve a heritage—whether it be the ocean or the Internet—for the next generation.

From Your Site Articles

- Political Backlash Ramps Up Digital Privacy Laws ›
- Privacy Is Just No Longer a Thing in Augmented Reality? ›
Related Articles Around the Web

- Maintaining Your Online Privacy | NIST ›
Barath Raghavan

Barath Raghavan coleads the networked systems lab at the University of Southern California, where he is an associate professor of computer science in the Virterbi School of Engineering. He recently cofounded INVISV to commercialize decoupled cloud-computing technologies.

Bruce Schneier

Bruce Schneier is a fellow at the Berkman Klein Center for Internet & Society at Harvard University, a lecturer in public policy at Harvard’s Kennedy School, and a board member of the Electronic Frontier Foundation. He has authored more than a dozen books, including his latest, A Hacker’s Mind.


