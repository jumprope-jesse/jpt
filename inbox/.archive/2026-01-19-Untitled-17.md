---
type: link
source: notion
url: https://www.lesswrong.com/posts/JfJvQze89ECArpFhx/a-brief-review-of-china-s-ai-industry-and-regulations
notion_type: Tech Deep Dive
tags: ['Running']
created: 2024-03-14T15:52:00.000Z
---

# Untitled

## Overview (from Notion)
- The rapid growth of China's AI industry and its regulatory landscape could impact global tech markets, influencing where you might invest or direct your company's focus.
- Understanding international AI regulations may help you navigate legal landscapes and ensure compliance if your software products or services reach global markets.
- The emphasis on "indigenous innovation" in China highlights a competitive landscape; fostering innovation in your own company could be crucial.
- The differing legal interpretations of AI-generated content, especially concerning copyright, could affect how you manage intellectual property in your software projects.
- The regulatory focus on algorithmic recommendations may prompt you to prioritize ethical considerations in your own products, especially if they utilize AI to personalize user experiences.
- Unique viewpoints include the idea that China's approach to AI governance is more about control than innovation, contrasting with the more open frameworks in Western countries.
- Alternate views stress that strict regulations may stifle innovation, while others argue that they create a safer and more trustworthy AI environment.
- The insights on public opinion towards AI in China suggest an opportunity to better understand user sentiment, which could inform your product development and marketing strategies.

## AI Summary (from Notion)
China's AI industry is rapidly growing, with significant regulations enacted since 2021 focusing on generative AI, deepfakes, and algorithmic recommendations. The government aims to shape technology to align with its political agenda while addressing social impacts and fostering innovation to become a global AI leader.

## Content (from Notion)

China has enacted three sets of AI regulations since 2021. I haven’t seen a concise breakdown of their content in one place, and I’ve been researching the legislation for a governance project at Convergence Analysis, so here is my concise summary of what I found. I’ll close each section by quoting some expert opinions on the legislation.

I’ll focus on what is being regulated rather than by which government agency, and I’ll omit what I consider “fluff”, such as the highlighted article 1 here. Also, note that I’m relying on other peoples’ translations and haven’t checked their quality. I’ve drawn from multiple translations for each point, but I wouldn’t rely on my precise parsing of the prose.

# China’s AI Industry

The AI industry in China is huge and growing rapidly, with a forecasted market size of $38.89 billion in 2024 (37% the size of the US’s forecasted market). China’s 2017 AI development plan states that AI has become a “focus of international competition”, and the 13th Five-Year Plan announced the goal for China to be a global AI leader by 2030. According to Stanford University’s DigiChina, a central concept in Xi Jinping’s leadership is “indigenous innovation” (自主创新), “building on a long-standing tradition of emphasizing self-reliance in industry and technology”.

Chinese AI research output is on par with US research output in share of top global publications and citations, according to a 2022 comparison by CSET. The 2023 AI Index Report found that 78% of Chinese citizens agreed that products & services using AI have more benefits than drawbacks - the highest proportion of surveyed countries, and more than double American citizens' 35% agreement.

Court rulings on AI and copyright are also different in China. In the US and the EU, material generated by AI can’t be copyrighted, but a Beijing court recently ruled that AI-generated content is copyrightable (note that some argue that precedent is less binding in the Chinese legal system, while others still expect this decision to have a huge impact).

Chinese researchers have developed several notable LLMs, such as Beijing Academy of Artificial Intelligence’s Wu Dao 2.0 in 2021 and Huawei Technologies’ PanGu-Σ in 2023. Wu Dao 2.0 has been called “world's largest model”, with some opining “Wu Dao 2.0 is 10x larger than GPT-3. Imagine what it can do” (see also Forbes and Politico). However, while Wu Dao 2.0 and PanGu-Σ did have more parameters than their concurrent occidental counterparts, that doesn’t mean they’re more powerful. Wu Dao 2.0 and PanGu-Σ use a different architecture called mixture of experts, in which different groups of parameters are used for different inputs.

MoE models are sparsely activated; only a fraction of the whole is active at once. Such models are computationally inexpensive relative to their number of parameters, but can be outperformed by smaller dense models. Ultimately, we don’t know how Wu Dao 2.0’s performance compares to others as its developers haven’t publicly released the model or whitepapers on its training & performance. Some claim that Wu Dao 2.0 beats GPT-3 on important benchmarks, while others argue that developers in China developers won’t be able to build competitive models for some time:

> China has neither the resources nor any interest in competing with the US in developing artificial general intelligence (AGI) primarily via scaling Large Language Models -  The AGI Race Between the US and China Doesn’t Exist by Eva_B

The US has responded to China’s growing AI industry in 2022 by imposing strict controls on exports of certain computer chips necessary for advanced AI, as well as the materials and methods necessary to manufacture their own chips. For more on this, check out CSIS’s report or, for a deep dive on the effects of chip embargos, Deric Cheng’s upcoming evaluation of AI chip registration policies.

## Scope and motivation

The Chinese government has numerous policies that are relevant to AI governance, but I’m only going to summarize the following three:

- 2023 legislation on generative AI (Interim Measures for the Management of Generative AI Services)
- 2022 legislation on deepfakes and similar tech (Provisions on the Administration of Deep Synthesis Internet Information Services)
- 2021 legislation on algorithmic recommendations (Provisions on the Management of Algorithmic Recommendations in Internet Information Services)
These are the three pieces of legislation we’re consulting for our upcoming report on the state of global AI governance. In particular, these three “contain the most targeted and impactful regulations to date, creating concrete requirements for how algorithms and AI are built and deployed in China” according to Matt Sheehan, author of a much deeper analysis of Chinese AI governance, which I’ll quote throughout this post such as now:

> [these regulations] share three structural similarities: the choice of algorithms as a point of entry; the building of regulatory tools and bureaucratic know-how; and the vertical and iterative approach that is laying the groundwork for a capstone AI law…Vertical regulations target a specific application or manifestation of a technology, [contrasting] horizontal regulations, such as the European Union’s AI Act, that are comprehensive umbrella laws attempting to cover all applications of a given technology.

Summarizing Sheehan’s analysis of the motivation behind these regulations, they serve 3 primary and 1 auxiliary functions:

- To shape technology to serve the CCP’s agenda for information control and political and social stability.
- To address the social, ethical, and economic impacts AI is having on people in China (for example, the provisions protecting workers whose schedules and salaries are set by algorithms).
- To create a policy environment conducive to China becoming the global leader in AI development and application.
# Interim Measures for the Management of Generative AI Services, 2023

Sources: Pillsbury law, Carnegie Endowment for International Peace, China Law Translate, DigiChina’s Translation, CASI Translation

Summary: Generative AI is to be both supported and regulated. GAI must adhere to core socialist values, respect protected characteristics, and adhere to IP & consent laws. Developers are responsible for violations, and must label GAI output in line with 2022 regulation. The government will support industry innovation and, on the international front, carry out fair exchange and participate in global AI regulation.

Terminology

- Generative AI services, or GAI services, refers to the use of generative AI to provide services to the public for the generation of text, images, audio, video, or other content.
- GAI providersproviders
- Public opinion propertiessocial mobilization capabilitiesprevious piece of legislation
Note that “public opinion properties” and “social mobilization capabilities” will both come up in the 2022 and 2021 legislation below, but I’ll only define them here.

### Chapter I: General Provisions

- These measures only apply to public-facing GAI in mainland China, excluding internal and non-public-facing use within businesses, research orgs, etc.
- The state places equal emphasis on development and security.
- The provision and use of GAI must:
### Chapter 2: Development and Governance of Technology

- The state will:
- When handling training data, GAI Providers must:
- When manually tagging (or labeling) data, GAI Providers must use clear and feasible rules, and carry out assessments & spot checks of labeling quality
### Chapter 3: Service Specifications

- GAI Providers bear responsibility as:
- Regarding their users, GAI Providers must:
- Regarding generated content, GAI Providers must:
- Providers must set up easy ways for users to lodge complaints.
### Chapter IV: Oversight Inspections and Legal Responsibility

- Relevant government departments are to strengthen the management of GAI services in accordance with law.
- Relevant national authorities are to improve scientific regulatory methods and formulate regulation guidelines.
- GAI providers offering services with public opinion properties or the social mobilization capabilities must carry out security self-assessments and file algorithms in accordance with 2022 legislation (see below).
- Users discovering law-breaking GAI services have the right to report this.
- GAI Providers must cooperate with oversight inspections of GAI services, explaining the data and technical aspects of their models.
- Those participating in oversight inspections mustn’t break confidentiality of state or commercial secrets or personal privacy.
- When GAI services from outside mainland China don’t meet these laws, this must be addressed by the state internet information department.
- Penalties for violating these measures should follow past legislation, or if that’s silent, relevant departments are to give warnings, circulate criticism, order corrections, and eventually to suspend the service.
### Commentary

Jenny Shang, Chunbin Xu, and Wenjun Cai at Pillsbury Law point out that the final version of the regulations are significantly lighter than early drafts, citing that:

> ...the new requirements:

Matt Sheehan at Carnegie, mentioned earlier, writes:

> By rolling out a series of more targeted AI regulations, Chinese regulators are steadily building up their bureaucratic know-how and regulatory capacity. Reusable regulatory tools like the algorithm registry can act as regulatory scaffolding that can ease the construction of each successive regulation, a particularly useful step as China prepares to draft a national AI law in the years ahead. [...]

Matt O’Shaugnessy, also at Carnegie, writes:

> Parts of the draft regulation would make real progress in shielding millions of people from potential harms of AI, if enforced in a uniform and meaningful way…these requirements bring to mind principles that are often promoted as supporting democratic values.

Qiheng Chen, on the topic of open-source models, writes:

> a notable gap in China’s generative AI regulations is the lack of specific guidance for open-source providers, which leads to ambiguity. The Interim Measures do not distinguish between open-source and API model providers. Imposing the same responsibilities on open-source and API providers could inadvertently hamper innovation.

# Provisions on the Administration of Deep Synthesis Internet Information Services, 2022

Sources: China Law Translate, DigiChina, Allenovery, China Briefing

Summary: Deepfakes and similar synthetic imagery, text, video, audio etc must respect social norms, and must not be used to harm the nation’s image or security interests; to spread false information; or to recreate someone’s image without consent. Synthetic output must be watermarked, and in many cases, conspicuously labeled.

Terminology

- Deep synthesis: This is sometimes interpreted as referring exclusively to deepfakes, but according to an official FAQ (also in article 2 of the draft here, or chapter V here), the term “deep synthesis technology” in the regulations refers to any technology that uses generative synthetic algorithms such as deep learning and virtual reality to produce text, images, audio (vocal and music), video, 3D construction and simulation.
- Deep synthesis service providers: Individuals or organizations who provide deep synthesis services (or provide technical support for them).
- Biometric information: Data about human bodies, e.g. a deepfaked face or voice.
### Chapter 1: General Provisions

- These provisions apply to the online use and provision of deep synthesis.
- Deep synthesis services must respect social mores and ethics and adhere to the correct political direction, public opinion orientation, and values trends.
- Industry organizations are encouraged to establish standards for self-management and accept societal oversight.
### Chapter II: Ordinary Provisions

- Deep synthesis must not be used to:
- Deep synthesis service providers must:
- App stores & other distributors must implement safety protocols and promptly handle any illegal deep synthesis service providers, e.g. through warnings or taking them off the market.
### Chapter III: Data and Technical Management Specifications

- Deep synthesis service providers must ensure the security of training data and protect personal information.
- When deep synthesis is used to edit biometric information (e.g. someone’s face or voice), they must prompt the user to notify and get consent from the person whose info is being edited.
- Where tools have the following functions, providers must carry out securitcy assessments:
- Providers must watermark the output of services.
- Providers must allow users to add conspicuous labels to the output of services.
- Providers must add conspicuous labels to the output of services when providing:
### Chapter IV: Oversight Inspections and Legal Responsibility

- Providers that have public opinion properties or capacity for social mobilization (see the 2021 legislation below) must conduct filing formalities within 10 working days of providing services and display their filing number prominently on their website, and must carry out necessary security assessments
- Internet, telecom, and public security departments may carry out oversight inspections of deep synthesis providers.
- When providers violate these provisions, they’re to be legally punished; where serious consequences were caused, give heavier penalties in accordance with law.
### Chapter V: Supplementary Provisions

- Article 23 defines the terminology introduced above; see here for the full detail.
- Providers must also comply with relevant provisions on culture and tourism, and radio and television.
- The rules take effect January 10th, 2023.
### Commentary

Matt Sheehan at Carnegie, quoted above also, provides some useful context for this legislation:

> The deep synthesis regulation was years in the making, but in the end it suffered from particularly poor timing. It was finalized on November 25, 2022, just five days before the release of ChatGPT.

Paol Triolo, technology policy lead at Albright Stonebridge, told CNBC:

> Chinese authorities are clearly eager to crack down on the ability of anti-regime elements to use deepfakes of senior leaders, including Xi Jinping, to spread anti-regime statement. But the rules also illustrate that Chinese authorities are attempting to tackle tough online content issues in ways few other countries are doing, seeking to get ahead of the curve as new technologies such as AI-generated content start to proliferate online.

Kendra Schaefer, partner at Trivium China, writes:

> China is able to institute these rules because it already has systems in place to control the transmission of content in online spaces, and regulatory bodies in place that enforce these rules. So, these rules underscore the policy problem of our age: How can Western democracies fight a war against disinformation and prevent the erosion of trust and truth online, but without resorting to censorship?

I’ll also note that I struggled to find any information on how these laws have been applied since coming into effect in early 2023. There seems to have been at least one case where a face-swapping app was court-ordered to issue an apology and compensate individuals who’d been wronged.

# Provisions on the Management of Algorithmic Recommendations in Internet Information Services, 2021

Sources: China Law Translate, DigiChina, Finnegan, Carnegie

Summary: Algorithms used to recommend content (e.g. a news feed in an app) must protect the rights of minors, the elderly, and workers.They must not spread false information, abuse their power, or disrupt economic or social order. Under some conditions, such algorithms must be registered with the government.

Terminology

- Algorithmic recommendation technology: The use of algorithm technologies types such as generation and synthesis, individualized pushing, sequence refinement, search filtering, schedule decision-making, and so forth to provide users with information.
- ARS: Algorithmic recommendation service, i.e. any service available to the public featuring algorithmic recommendation technology.
### Chapter I: General Provisions

- These provisions apply to ARSs online within mainland China.
- ARSs must obey laws, social mores, ethics, and the principles of equity, fairness, transparency, rationality, reasonableness.
- Industry organizations are encouraged to strengthen industry discipline, establish standards for self-management, and accept societal oversight.
### Chapter II: Regulation of Information Services

- ARS providers shall uphold mainstream values, actively spread positive energy, and promote the positive use of algorithms.
- ARS providers must not use ARSs to:
- ASR providers must:
### Chapter III: User Rights Protection

- ARS providers must provide users with:
- When ARSs are provided to minors (under 18):
- ARS providers must respect the lawful rights and act supportively towards the elderly and workers whose income depends on them (e.g. delivery workers subject to algorithmic scheduling or price discrimination)..
- ARS operators shall make it easy for users to register complaints.
### Chapter IV: Supervision and Management

- Appropriate departments are to establish a categorized algorithm security management system, based on the ARS’s public opinion properties, social mobilization capability, content categories, scale of users, the importance of data handled etc.
- Providers of ARSs with public opinion properties or social mobilization capabilities must register (and maintain the filing of) their algorithm with the government, including submitting a self-assessment report and a security assessment.
- The Cybersecurity department will conduct algorithm security assessments on ARSs.
- Providers must preserve records of their network and support governmental investigators.
### Chapter V: Legal Liability

- This section prescribes the legal consequences of breaking different sets of these articles, including the possibility of criminal liability and fines up to 100,000 yuan ($14,000 USD)
### Chapter VI: Supplementary provisions

- Article 35: These Provisions take effect on March 1, 2022.
### Commentary

Matt Sheehan at Carnegie, quoted above also, writes:

> The term ‘algorithmic recommendation’ [...] first emerged during a 2017 CCP backlash against ByteDance’s news and media apps, in which user feeds were dictated by algorithms. The party viewed this as threatening its ability to set the agenda of public discourse and began looking for ways to rein in algorithms used for information dissemination […]

Lionel Lavenue, Joseph Myles, and Andrew Schneider at Finnegan write about international law implications of this legislation compared to previous legislation (the DSL & PIPL):

> the regulations may allow Chinese litigants to refuse or delay discovery. For example, in [a 2021 court case], Chinese-based defendant ZHP invoked the DSL and the PIPL to avoid producing documents, arguing that the documents at issue were “state secrets.” In a published opinion on the issue, Judge Robert B. Kugler held that the PIPL and DSL did not shield discovery, and he warned that Chinese defendants must “know from the outset they risk serious consequences if and when they fail to obey a U.S. court’s order to compel discovery [...] the IISARM regulations add another layer of bureaucracy. Thus, if litigants want to obtain information for discovery from China, they are likely to run into new administrative slowdowns.

Steven Rolf, author of China's Regulations on Algorithms, compares these regulations with the draft EU AI Act (note that the draft EU act has since undergone significant redrafting):

> The major distinguishing feature of [the EU AI Act] is its emphasis on upholding fundamental individual rights – such as privacy, ethical decision-making and data security – against (principally US-based) tech firms [...] From the perspective of individuals, then, Europe’s regulatory drive is preferable to that of China’s – which places little emphasis on privacy or fundamental rights. But it does little to tackle issues beyond individual concerns. As one report argues, recommendation algorithms ‘may cause societal-level harms, even when they cause only negligible harms to individuals’ (by, for instance, tipping the balance in an election by discouraging wavering voters from turning out) [...] Even in an age of growing algorithmic regulation, then, China’s ‘social’ model contrasts with the emerging ‘individualist’ European regulatory model. China’s emergent regulatory system targets areas hardly touched by Europe’s flagship regulations

For more information on other Chinese legislation that may relate to AI, check out Making Sense of China’s AI Regulations by Ashyana-Jasmine Kachra at Holistic AI, which also features concise summaries of China’s AI industry and legislation with lovely visuals, and which was published only after I’d written the majority of this post, alas.

Thank you to Deric Cheng for his encouragement, and Deric and Justin Bullock for their feedback on this post.

If you’re interested in global AI legislation, over the next few months we’ll be publishing deep dives into topics like AI chip registration policies, and a series of posts analyzing EU, Chinese, and US AI legislation on specific topics such as model registries and risk assessments. You can find the first post here: AI Regulatory Landscape Review: Incident Reporting. Ultimately, this research will culminate in a State of the AI Regulatory Landscape in 2024 report later this year. If you’d like to get updates on this work, check out Convergence Analysis and sign up to our newsletter!


