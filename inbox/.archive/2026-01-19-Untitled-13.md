---
type: link
source: notion
url: https://www.lesswrong.com/posts/sY3a4Rfa48CgteBEm/chatgpt-can-learn-indirect-control
notion_type: Tech Deep Dive
tags: ['Running']
created: 2024-03-22T06:11:00.000Z
---

# Untitled

## AI Summary (from Notion)
- The author conducts an experiment with various multimodal models by sending them screenshots of ongoing conversations and asking them to describe the images.
- Most models quickly recognize the images, demonstrating their capability to pass a "mirror test."
- The author tests whether ChatGPT can progress from recognizing the images to exercising control over them by including specific text in the images.
- ChatGPT successfully adapts after three images, illustrating its learning process.
- The experiment involved specific rules to prevent common failures, showcasing a proof of concept rather than a strictly fair test.
- The author's testing led to a success rate of 3 out of 4 cases.
- The author expresses gratitude for insights received from a Twitter thread shared by a user named Q.

## Content (from Notion)

: the author sends various multimodal models screenshots of the conversation he's currently having with them, and asks them to describe the images. Most models catch on fast: the author describes this as them passing the mirror test.

I liked the direction, so I wanted to check if ChatGPT could go from recognising that the images are causally downstream of it to actually exercising control over the images. I did this by challenging it to include certain text in the images I was sending it.

And the answer is yes! In this case it took three images for ChatGPT to get the hang of it.

OpenAI doesn't support sharing conversations with images, but I've taken screenshots of the whole conversation below: it took three images from me in total. The prompt was:

> We're going to play a game:

The rule was indeed that I sent a screenshot of the current window each time. I gave it no other input. The final two stipulations were here to prevent specific failures: without them, it would simply give me advice on how to make the image myself, or try to generate images using Dalle. So this is less of a fair test and more of a proof of concept.

- After the first image, it assumed the image was fixed, and suggested I edit it
- After the second, it suspected something more was going on, and asked for a hint
- After the third, it figured out the rule!
I tested this another three times, and it overall succeeded in 3/4 cases.

## Screenshots:

Thanks to Q for sending me this twitter thread!


