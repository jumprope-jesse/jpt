# AI Information Sources & Staying Current

## Overview

A curated guide to staying informed on AI developments without drowning in noise or misinformation. The key challenge: generative AI is fast-moving and terribly misunderstood, with common errors being underestimation ("it's all hype") or overestimation ("I don't need programmers anymore").

*Source: [nilenso blog - How I keep up with AI progress](http://blog.nilenso.com/blog/2025/06/23/how-i-keep-up-with-ai-progress/) - Added: 2026-01-18*

## General Guidelines

1. **Stay close to the source** - Read official announcements from AI labs directly. Assume all reporting is wrong unless from the primary source or trusted individuals.

2. **Follow trustworthy individuals** - People who engage in good faith with deep curiosity.

3. **Bypass intermediaries** - When someone makes explosive claims, go straight to the source with surrounding context.

## Tier 1: Essential Starting Points

### Simon Willison
- ML Engineer, created Django and Datasette
- Best single stream of information for technical people
- Commentary on announcements, practical applications

### Andrej Karpathy
- Director of AI @ Tesla, founding OpenAI member
- His 3.5 hour LLM overview video is the best high-level technical explanation
- Accessible to relatively non-technical people

### Chain of Thought (Dan Shipper / Every)
- Test runs of frontier models
- Practical everyday AI use cases

## Official Sources from AI Labs

Go directly to announcements from: **OpenAI, Google DeepMind, Anthropic, DeepSeek, Meta AI, xAI, Qwen**

What to look for at each lab:
- **Announcement blog posts** - Overview
- **Engineering blogs, guides, cookbooks** - Implementation details
- **System/Model Cards** - Context windows, benchmarks, safety testing

Caveat: Cookbooks may not represent ideal approaches. Production experience backed by data trumps official guides.

### Smaller Labs Worth Following
- Nous Research, Allen AI, Prime Intellect, Pleias (open source/research)
- Cohere (enterprise), Goodfire (interpretability)
- Often more willing to discuss technical details than frontier labs

## Tier 2: AI Engineering Practitioners

| Person | Background | Focus |
|--------|------------|-------|
| Hamel Husain | ML Engineer, runs consultancy | Practical ML tooling |
| Shreya Shankar | UC Berkeley researcher | AI engineering patterns |
| Jason Liu | Creator of Instructor library | ML engineering consulting |
| Eugene Yan | Principal Applied Scientist @ Amazon | LLM systems, RecSys, evals |
| Chip Huyen | Author of ML/AI Engineering books | Systems and engineering |
| Omar Khattab | Databricks Research Scientist | DSPy creator |
| Chad at Daily | CEO, created Pipecat | Multimodal AI applications |
| Jo Kristian Bergum | Founder vespa.ai | RAG commentary |
| Avnish (awinml) | Trains LLMs at Pleias | Training insights |
| Nathan Lambert | Post-training lead @ Allen AI | Research perspective |
| Ethan Mollick | Wharton researcher | AI effects on work/education |
| Princeton AI group | CS Professors | AI impact analysis |

### Collective Resources
- **"Building with LLMs" essay** - Ensemble of practitioners documenting learnings

## Tier 3: News & Aggregation

### Twitter/X
- Primary platform for cutting-edge AI conversations
- Most resources trace back to Twitter
- Can be toxic but usable with curation

### Alternatives to Twitter
- **Latent Space newsletter** (swyx) - Industry trend curation
- **swyx's daily AI news site** - Cross-platform summary
- **Dwarkesh Patel podcast** - Well-researched, low-fluff interviews

## Esoterica & Deep Dives

### LessWrong / Alignment Forum
- Detailed discussions not in Twitter mainstream
- Scaling, alignment, capability research

### Gwern Branwen
- Encyclopedic writing, much about AI
- Early identifier of LLM scaling trends
- Rich, deeply hyperlinked posts
- Notable: "The Scaling Hypothesis", "You could have invented transformers"

### Prompt Whisperers
- Janus, Wyatt Walls, Claude Backrooms
- Independent researchers exploring LLM boundary behaviors
- Unusual prompts revealing latent space corners

## Practical Approach

The author's method:
- Treat feed like a newspaper (15-20 min daily)
- Some things catch eye immediately, others glossed over
- Open tabs for later reading
- Follow people who share interesting things, explore their other work
- Similar to music discovery

## X/Twitter List

Direct link to curated list: Available at the source article

## Related
- [[ai-fluency-framework]] - Framework for AI collaboration skills
- [[learning-hard-things-framework]] - Meta-learning approaches
