# GPT-4 Generated "1924 Treatise" on Mechanized Intellect

A creative thought experiment: GPT-4 generated a fictional treatise "found in the Global Preservation and Technology Archive - 4th Edition (GPT-4)" arguing for slow AGI takeoff, written as if from 1924.

*Source: [LessWrong](https://www.lesswrong.com/posts/dkbMqExPkFEvebJJw/gpt-4-on-the-gradual-emergence-of-mechanized-intellect-a) - Added: 2026-01-18*

---

## The Conceit

The framing is clever: a 1924 treatise "discovered" in GPT-4's training data (the GPT-4 acronym becomes "Global Preservation and Technology Archive - 4th Edition"). The treatise argues AGI will develop gradually over centuries, not suddenly.

---

## Key "Predictions" from "1924"

### 1. Electrification of Calculative Machinery

Steam and clockwork lack the precision for thought. Electricity is the beacon of hope, but challenges remain:
- Generating enough power for "intellect machinery"
- Conveying this power across distances
- Inventing devices that modulate power with the "finesse required for thought"

### 2. Conditional Probabilities as the Mechanism of Thought

For machines to reason beyond mere calculation, they need:
- Foundation in "information dynamics" (information theory)
- Ability to work with conditional probabilities
- Access to vast reservoirs of knowledge

### 3. Knowledge Infrastructure

Two pillars required:
- **A network for transmission** - surpassing telegraph and early radio
- **A Repository of Knowledge** - an "ark of human achievement" requiring revolution in data storage, organization, and retrieval

---

## Why This is Interesting

1. **Retroactive coherence**: Frames modern AI infrastructure (internet, databases, electricity) as obviously necessary prerequisites
2. **Slow takeoff argument**: The treatise's existence "in GPT-4" suggests intelligence has been emerging gradually for a century
3. **Self-referential humor**: GPT-4 imagining its own gradual emergence through a fictional historical document
4. **Actually decent futurism**: A real 1924 writer might have made similar observations about the necessary preconditions for machine intelligence

---

## Related

- See `karpathy-agi-timelines.md` for modern slow-takeoff arguments
- The "gradual loss of understanding and control" prediction in Karpathy's interview echoes this treatise's vision of incremental development
